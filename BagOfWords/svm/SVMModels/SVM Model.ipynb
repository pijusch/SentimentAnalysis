{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "#Open file in read-only and extract content into variable 'content'\n",
    "def loadFile(filename):\n",
    "    openFile = open(filename, 'r')\n",
    "    content = openFile.read()\n",
    "    openFile.close()\n",
    "    return content\n",
    "\n",
    "#Tokenize file\n",
    "def tokenizeFile(filename):\n",
    "    tokens = filename.split()                                   #remove whitespace\n",
    "    tokens = [x.strip(string.punctuation) for x in tokens]           #remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]        #remove none alphabetic words\n",
    "    stopWords = set(stopwords.words('english'))                 #remove stop words\n",
    "    tokens = [word for word in tokens if not word in stopWords]\n",
    "    tokens = [word for word in tokens if len(word) > 1]         #remove 1-letter tokens\n",
    "    return tokens\n",
    "\n",
    "#Convert tokens to single strings for easier encoding\n",
    "def fileToLine(filename, vocab):\n",
    "    content = loadFile(filename)\n",
    "    tokens = tokenizeFile(content)\n",
    "    tokens = [word for word in tokens if word in vocab]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Load all reviews and start mapping words to counter\n",
    "def loadReviews(directory, vocab, is_train):\n",
    "    lines = list()\n",
    "    for filename in listdir(directory):\n",
    "        if filename.startswith('cv9') and is_train:\n",
    "            continue\n",
    "        if not filename.startswith('cv9') and not is_train:\n",
    "            continue\n",
    "        path = directory + '/' + filename\n",
    "        line = fileToLine(path, vocab)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "#Predict reviews based on MLP network\n",
    "def predictReview(review, vocab, tokenizer, model):\n",
    "\n",
    "    #Split review into words and filter based on current vocab\n",
    "    tokens = tokenizeFile(review)\n",
    "    tokens = [word for word in tokens if word in vocab]\n",
    "    lines = ' '.join(tokens)\n",
    "    encode = tokenizer.texts_to_matrix([lines], mode='freq')\n",
    "\n",
    "    #Predict review: 0 if positive, 1 if negative\n",
    "    y = model.predict(encode, verbose=0)\n",
    "    return round(y[0,0])\n",
    "\n",
    "\n",
    "### Main ###\n",
    "vocabFile = 'vocab.txt'\n",
    "vocab = loadFile(vocabFile)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "\n",
    "#Training set\n",
    "pos_reviews = loadReviews('data/pos', vocab, True)\n",
    "neg_reviews = loadReviews('data/neg', vocab, True)\n",
    "tokenizer = Tokenizer()\n",
    "total = pos_reviews+neg_reviews\n",
    "tokenizer.fit_on_texts(total)\n",
    "x_train = tokenizer.texts_to_matrix(total, mode='freq')\n",
    "y_train = array([0 for _ in range(900)] + [1 for _ in range(900)])\n",
    "\n",
    "#Testing Set\n",
    "pos_reviews = loadReviews('data/pos', vocab, False)\n",
    "neg_reviews = loadReviews('data/neg', vocab, False)\n",
    "total = pos_reviews+neg_reviews\n",
    "x_test = tokenizer.texts_to_matrix(total, mode='freq')\n",
    "y_test = array([0 for _ in range(100)] + [1 for _ in range(100)])\n",
    "\n",
    "#Define MLP network\n",
    "nWords = x_test.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(nWords,), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compile and Fit network to training data\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=30, verbose=2)\n",
    "\n",
    "#Evaluate network on testing data\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test data accuracy: %f' % (acc*100))\n",
    "\n",
    "# Sample reviews - EDIT THIS TO TEST MLP NETWORK (0 if positive, 1 if negative)\n",
    "text1 = \"The first film, a frenetic and hilarious tribute to superhero films and imbued with 1950s style, was an absolute masterpiece, with great characters and hugely inventive action set pieces. This one is a worthy successor. Thatâ€™s all you need to know\"\n",
    "print(predictReview(text1, vocab, tokenizer, model))\n",
    "\n",
    "text2 = \"I'm not usually a fan of suspenseful movies, but this one surprised me in a lot of ways. Of course, it's not without its shortcomings: the foil is pretty easy to spot early on, and the monster is fairly unimaginative, but there's a beauty in its simplicity, particularly in the family's story, that draws you in.John Krasinski does it all, providing a great performance and excellent direction of himself and his peers. Even though it's never one to subvert your expectations, the thrill of seeing it all unfold is very enjoyable. Though I didn't particularly enjoy the ending, I thought the rest of the film was strong enough to make up for it.What it does well: The quiet, honestly, is done perfectly. It's not abused with jump scares, and really feels as if it's its own character.What it could improve on:Itwill, almost certainly, leave you with some questions.Why didn't they just do this?was a common discussion topic among my group.\"\n",
    "print(predictReview(text2, vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Load data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
